{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78c12340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from itertools import combinations\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeat\n",
    "from cartopy.util import add_cyclic_point\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c1c607d",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6e91899",
   "metadata": {},
   "outputs": [],
   "source": [
    "FID_label = ['AR','FT','MCS','LPS','AF','AM','AL','FM','FL','ML','AFM','AFL','AML','FML','All','UE','DC','CG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b473639d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_fid_update(data_fid_mask, front_replace=False):\n",
    "    \n",
    "    \"\"\" updating the origional FID data by adding DC and CG\n",
    "        set front_replace = True to replace FT and FT-associated labels over the tropics\n",
    "        input: data_fid_mask (time, lat, lon), feat_comb_label\n",
    "    \"\"\"\n",
    "\n",
    "    data_fid_label = data_fid_mask.feat_comb_label\n",
    "    data_dc_mask = data_fid_mask.deep_conv_mask # (0,1)\n",
    "    data_cg_mask = data_fid_mask.nondeep_conv_mask + 1 # now is (1,2) instead for later screening processes \n",
    "    \n",
    "    if front_replace == False:\n",
    "    \n",
    "        data_dc_label = data_dc_mask.where((data_dc_mask == 1) & (data_fid_label == 16), 0)\n",
    "        data_cg_label = data_cg_mask.where((data_cg_mask == 2) & (data_fid_label == 16), 0)\n",
    "\n",
    "        data_fid_final = data_fid_label + data_dc_label + data_cg_label # now ranges from 1 to 18    \n",
    "    \n",
    "    if front_replace == True:\n",
    "        \n",
    "        ### ad-hoc approach to mask out \"FT\" and the associated over the tropics\n",
    "        FID_label = ['AR','FT','MCS','LPS','AF','AM','AL','FM','FL','ML','AFM'\n",
    "                     ,'AFL','AML','FML','All','UE','DC','CG']\n",
    "        idx_F = []\n",
    "        for n,fid in enumerate(FID_label):\n",
    "            for char in fid:\n",
    "                if (char == 'F') or (char == 'l'): # label with front and All\n",
    "                    idx_F.append(n+1)\n",
    "                    break\n",
    "        idx_F_replace = [16, 1, 3, 4, 6, 7, 10, 13] # convert to: UE, AR, MCS, LPS, AM, AL, ML, AML\n",
    "    \n",
    "        # keep mid-high latitudes\n",
    "        dum1 = data_fid_label.where((data_fid_label.latitude >= 20), 0)\n",
    "        dum2 = data_fid_label.where((data_fid_label.latitude <= -20), 0)\n",
    "        data_fid_extra = dum1 + dum2\n",
    "        \n",
    "        # keep tropics for unaffected labels\n",
    "        cond_tropics = (data_fid_label.latitude < 20) & (data_fid_label.latitude > -20)\n",
    "        data_fid_tropics = data_fid_label.where(cond_tropics, 0)\n",
    "\n",
    "        data_fid_list = []\n",
    "        for label_F, label_replace in zip(idx_F, idx_F_replace):\n",
    "\n",
    "            data_fid_unique = data_fid_label.copy()\n",
    "            data_fid_unique = data_fid_unique.where(data_fid_unique == label_F, 0)\n",
    "            data_fid_unique = data_fid_unique.where(data_fid_unique == 0, label_replace) \n",
    "            data_fid_unique = data_fid_unique.where(cond_tropics, 0)\n",
    "\n",
    "            data_fid_list.append(data_fid_unique)\n",
    "\n",
    "        data_fid_null = data_fid_unique*0 # empty to be filled\n",
    "        for data_replace in data_fid_list:\n",
    "\n",
    "            data_fid_null += data_replace \n",
    "        data_fid_update = data_fid_extra + data_fid_tropics + data_fid_null\n",
    "        \n",
    "        # final step: adding DC & CG\n",
    "        data_dc_label = data_dc_mask.where((data_dc_mask == 1) & (data_fid_update == 16), 0)\n",
    "        data_cg_label = data_cg_mask.where((data_cg_mask == 2) & (data_fid_update == 16), 0)\n",
    "\n",
    "        data_fid_final = data_fid_update + data_dc_label + data_cg_label # now ranges from 1 to 18  \n",
    "        \n",
    "        ######## issues to be solved #####\n",
    "        data_fid_final = data_fid_final.where(data_fid_final <= 18, 0)\n",
    "    \n",
    "    return data_fid_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9c2f6884",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "year =2004\n",
    "\n",
    "data_dir = Path('/neelin2020/RGMA_feature_mask/data_product/{}/MERGED_FP'.format(year))\n",
    "\n",
    "files = sorted(list(data_dir.glob('*_expand.nc')))\n",
    "data_FP_merged = xr.open_mfdataset(files)\n",
    "data_gpm = data_FP_merged.precipitationCal.sel(longitude=np.arange(0,360,0.25))\n",
    "\n",
    "# add post-defined deep convection and congestus\n",
    "files = sorted(list(data_dir.glob('*_convmask.nc')))\n",
    "data_fid_mask = xr.open_mfdataset(files)\n",
    "data_dc_mask = data_fid_mask.deep_conv_mask # (0,1)\n",
    "data_cg_mask = data_fid_mask.nondeep_conv_mask + 1 # now is (1,2) instead for later screening processes\n",
    "\n",
    "data_fid_update = process_data_fid_update(data_fid_mask, front_replace=True)\n",
    "\n",
    "# update data_gpm: some minor mismatches, so make sure the sum of total explained equals to 1\n",
    "data_gpm_tmatch = data_gpm.sel(time=data_fid_update.time)\n",
    "data_gpm_tmatch = data_gpm_tmatch.where(data_fid_update > 0, 0)\n",
    "\n",
    "explained_pcp_list = []\n",
    "\n",
    "for fid, fid_name in zip(np.arange(1,19), FID_label): # 1-18 for defined FIDs\n",
    "\n",
    "    dum = data_fid_update.copy()\n",
    "    dum2 = data_gpm_tmatch.where(dum == fid, 0) # extract only pixels associated with the specified FID    \n",
    "\n",
    "    explained_precip = (dum2.sum('time')/data_gpm_tmatch.sum('time')).compute() # how much rain amount explained by specific type\n",
    "    explained_pcp_pid = explained_precip.to_dataset().rename_vars({'precipitationCal':'pcp_explained'})\n",
    "    explained_pcp_list.append(explained_pcp_pid)\n",
    "    \n",
    "explained_pcp_xr = xr.concat(explained_pcp_list, pd.Index(FID_label, name='feature_id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "975cabef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing year: 2001\n",
      "processing year: 2002\n",
      "processing year: 2003\n",
      "processing year: 2004\n",
      "processing year: 2005\n",
      "processing year: 2006\n",
      "processing year: 2007\n",
      "processing year: 2008\n",
      "processing year: 2009\n",
      "processing year: 2010\n",
      "processing year: 2011\n",
      "processing year: 2012\n",
      "processing year: 2013\n",
      "processing year: 2014\n",
      "processing year: 2015\n",
      "processing year: 2016\n",
      "processing year: 2017\n",
      "processing year: 2018\n",
      "processing year: 2019\n",
      "CPU times: user 7h 21min 29s, sys: 10h 40min 43s, total: 18h 2min 12s\n",
      "Wall time: 3h 12min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "year_list = np.arange(2001,2020) # 2001-2019\n",
    "\n",
    "explained_pcp_multiyr = []\n",
    "\n",
    "for year in year_list:\n",
    "\n",
    "    print('processing year: {}'.format(year))\n",
    "    \n",
    "    data_dir = Path('/neelin2020/RGMA_feature_mask/data_product/{}/MERGED_FP'.format(year))\n",
    "\n",
    "    files = sorted(list(data_dir.glob('*_expand.nc')))\n",
    "    data_FP_merged = xr.open_mfdataset(files)\n",
    "    data_gpm = data_FP_merged.precipitationCal.sel(longitude=np.arange(0,360,0.25))\n",
    "\n",
    "    files = sorted(list(data_dir.glob('*_convmask.nc')))\n",
    "    data_fid_mask = xr.open_mfdataset(files)\n",
    "\n",
    "    # add post-defined deep convection and congestus and repalce FT over tropics \n",
    "    data_fid_update = process_data_fid_update(data_fid_mask, front_replace=True)\n",
    "\n",
    "    # update data_gpm: some minor mismatches, so make sure the sum of total explained equals to 1\n",
    "    data_gpm_tmatch = data_gpm.sel(time=data_fid_update.time)\n",
    "    data_gpm_tmatch = data_gpm_tmatch.where(data_fid_update > 0, 0)\n",
    "\n",
    "    explained_pcp_list = []\n",
    "\n",
    "    for fid, fid_name in zip(np.arange(1,19), FID_label): # 1-16 for defined FIDs\n",
    "\n",
    "        dum = data_fid_update.copy()\n",
    "        dum2 = data_gpm_tmatch.where(dum == fid, 0) # extract only pixels associated with the specified FID    \n",
    "\n",
    "        explained_precip = (dum2.sum('time')/data_gpm_tmatch.sum('time')).compute() # how much rain amount explained by specific type\n",
    "        explained_pcp_pid = explained_precip.to_dataset().rename_vars({'precipitationCal':'pcp_explained'})\n",
    "        explained_pcp_list.append(explained_pcp_pid)\n",
    "\n",
    "    explained_pcp_multiyr.append(xr.concat(explained_pcp_list, pd.Index(FID_label, name='feature_id')))\n",
    "        \n",
    "explained_pcp_multiyr_xr = xr.concat(explained_pcp_multiyr, pd.Index(year_list, name='year'))\n",
    "explained_pcp_multiyr_xr.to_netcdf('/neelin2020/RGMA_feature_mask/data_product/multi_year_stats/explained_pcp_2001_2019_RmTroFT.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21ac35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_pcp_multiyr_xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8159b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed766642",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
